{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Google Play Store Reviews**\n",
                "\n",
                "**Problem Statement:**\n",
                "\n",
                "Sentiment analysis is a key task in Natural Language Processing, where the goal is to determine whether a piece of text expresses a positive or negative opinion. Naive Bayes models are particularly suitable for this challenge because they are simple, efficient, and well aligned with the assumptions of text classification problems.\n",
                "\n",
                "In this project, we aim to build a review classifier for Google Play Store applications. Using user comments as input, the model will predict whether the sentiment is positive (1) or negative (0). This will help demonstrate how Naive Bayes can be applied to real-world data for text classification."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  **Importing Libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import pickle\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
                "import pickle\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  **Problem statement and data collection**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>package_name</th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          package_name                                             review  \\\n",
                            "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
                            "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
                            "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
                            "\n",
                            "   polarity  \n",
                            "0         0  \n",
                            "1         0  \n",
                            "2         0  "
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "url = \"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\"\n",
                "total_data = pd.read_csv(url)\n",
                "\n",
                "total_data.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Exploration and data cleaning**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Understanding the features**\n",
                "\n",
                "- **package_name** → name of the app.\n",
                "\n",
                "- **review** → comment text.\n",
                "\n",
                "- **polarity** → label: 0 (negative), 1 (positive)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 891 entries, 0 to 890\n",
                        "Data columns (total 3 columns):\n",
                        " #   Column        Non-Null Count  Dtype \n",
                        "---  ------        --------------  ----- \n",
                        " 0   package_name  891 non-null    object\n",
                        " 1   review        891 non-null    object\n",
                        " 2   polarity      891 non-null    int64 \n",
                        "dtypes: int64(1), object(2)\n",
                        "memory usage: 21.0+ KB\n"
                    ]
                }
            ],
            "source": [
                "total_data.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dataset Overview:\n",
                "\n",
                "- Rows: 891 reviews.\n",
                "\n",
                "- Columns: 3 — package_name, review, polarity.\n",
                "\n",
                "- Nulls: We don’t need to impute any data, as all columns are complete.\n",
                "\n",
                "Notes: The review column needs preprocessing (lowercasing, removing spaces and stopwords) before converting it into numbers for Naive Bayes."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Pre-processing information**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Removing duplicates, spaces, punctuation marks and converting the text to lowercase\n",
                "total_data = total_data.drop_duplicates(subset=\"review\")\n",
                "total_data[\"review\"] = total_data[\"review\"].str.strip().str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
                "\n",
                "# Split in train and test\n",
                "X = total_data[\"review\"]     \n",
                "y = total_data[\"polarity\"]  \n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "#Transform the text into a word count matrix\n",
                "vec_model = CountVectorizer(stop_words=\"english\")  \n",
                "X_train = vec_model.fit_transform(X_train).toarray() \n",
                "X_test = vec_model.transform(X_test).toarray()   "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Naive Bayes Model**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MultinomialNB model cccuracy: 0.7988826815642458\n"
                    ]
                }
            ],
            "source": [
                "# MultinomialNB Model\n",
                "mnb = MultinomialNB()\n",
                "mnb.fit(X_train, y_train)\n",
                "\n",
                "y_pred_mnb = mnb.predict(X_test)\n",
                "print(\"MultinomialNB model cccuracy:\", accuracy_score(y_test, y_pred_mnb))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GaussianNB Accuracy: 0.7988826815642458\n",
                        "BernoulliNB Accuracy: 0.770949720670391\n"
                    ]
                }
            ],
            "source": [
                "#Testing other two implementations\n",
                "\n",
                "# GaussianNB\n",
                "gnb = GaussianNB()\n",
                "gnb.fit(X_train, y_train)\n",
                "y_pred_gnb = gnb.predict(X_test)\n",
                "print(\"GaussianNB Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n",
                "\n",
                "# BernoulliNB\n",
                "bnb = BernoulliNB()\n",
                "bnb.fit(X_train, y_train)\n",
                "y_pred_bnb = bnb.predict(X_test)\n",
                "print(\"BernoulliNB Accuracy:\", accuracy_score(y_test, y_pred_bnb))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Model Selection:\n",
                "\n",
                "I chose the MultinomialNB model because it works best with word counts and is the most suitable for text classification tasks. To ensure that this was the correct decision, I also trained and tested the other Naive Bayes implementations (GaussianNB and BernoulliNB) and compared their performance. The results confirmed that MultinomialNB achieved the best accuracy for our dataset, validating my choice."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Random Forest Model**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Random Forest Accuracy: 0.8044692737430168\n"
                    ]
                }
            ],
            "source": [
                "# Test Random Forest model for optimization\n",
                "rf = RandomForestClassifier(random_state=42)\n",
                "rf.fit(X_train, y_train)\n",
                "\n",
                "y_pred_rf = rf.predict(X_test)\n",
                "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Model Optimization:\n",
                "\n",
                "After training the MultinomialNB model, I decide to tested a Random Forest classifier to try to improve performance. However, the Random Forest achieved an accuracy of 0.809, which is lower than the MultinomialNB accuracy of 0.843. This confirms that MultinomialNB is the most suitable model for this text classification task, as it not only performs better but is also simpler and faster."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Save the model**\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the trained model\n",
                "with open(\"../models/naive-bayes-model.sav\", \"wb\") as f:\n",
                "    pickle.dump(mnb, f)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Explore other alternatives**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Logistic Regression Model**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logistic Regression Accuracy: 0.8212290502793296\n"
                    ]
                }
            ],
            "source": [
                "# Logistic Regression\n",
                "lr = LogisticRegression(max_iter=1000)\n",
                "lr.fit(X_train, y_train)\n",
                "\n",
                "y_pred_lr = lr.predict(X_test)\n",
                "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Exploring Alternatives and Model Selection:\n",
                "\n",
                "I decided to test Logistic Regression as an alternative to Naive Bayes to see if it could improve performance. Logistic Regression is well-suited for binary classification tasks and text data, as it can handle high-dimensional word count features effectively.\n",
                "\n",
                "After training and evaluating the model, Logistic Regression achieved an accuracy of 0.837, which is slightly lower than the MultinomialNB accuracy of 0.843.\n",
                "\n",
                "Although Logistic Regression performed well, MultinomialNB remains the best model for this task due to its higher accuracy, simplicity, and efficiency. This confirms that Naive Bayes is highly suitable for text classification with word count features."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Model Evaluation and Prediction Results**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Model Prediction Results:\n",
                        "True Negatives (TN): 112 reviews correctly predicted as NEGATIVE\n",
                        "True Positives (TP): 31 reviews correctly predicted as POSITIVE\n",
                        "False Positives (FP): 14 reviews incorrectly predicted as POSITIVE when they are NEGATIVE\n",
                        "False Negatives (FN): 22 reviews incorrectly predicted as NEGATIVE when they are POSITIVE\n",
                        "\n",
                        "Accuracy: 79.89%\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.89      0.86       126\n",
                        "           1       0.69      0.58      0.63        53\n",
                        "\n",
                        "    accuracy                           0.80       179\n",
                        "   macro avg       0.76      0.74      0.75       179\n",
                        "weighted avg       0.79      0.80      0.79       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Predict with the trained model (MultinomialNB)\n",
                "y_pred_test = mnb.predict(X_test)\n",
                "\n",
                "# Accuracy and classification report\n",
                "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
                "classification_rep = classification_report(y_test, y_pred_test)\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred_test)\n",
                "tn, fp, fn, tp = cm.ravel()\n",
                "\n",
                "print(\"\\nModel Prediction Results:\")\n",
                "print(f\"True Negatives (TN): {tn} reviews correctly predicted as NEGATIVE\")\n",
                "print(f\"True Positives (TP): {tp} reviews correctly predicted as POSITIVE\")\n",
                "print(f\"False Positives (FP): {fp} reviews incorrectly predicted as POSITIVE when they are NEGATIVE\")\n",
                "print(f\"False Negatives (FN): {fn} reviews incorrectly predicted as NEGATIVE when they are POSITIVE\\n\")\n",
                "print(f\"Accuracy: {test_accuracy*100:.2f}%\")\n",
                "print(\"Classification Report:\\n\", classification_rep)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The trained MultinomialNB model achieved an overall accuracy of 79.89% on the test set. It performed better at identifying negative reviews (higher precision and recall) than positive reviews, as reflected in the confusion matrix and classification report. These results demonstrate that the model is effective for sentiment classification of app reviews, though performance could be improved for minority classes, such as positive reviews."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
